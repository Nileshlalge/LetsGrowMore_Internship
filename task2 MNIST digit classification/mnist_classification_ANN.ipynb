{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65766a00-cdb1-4d5e-a0f6-e77d75a22b47",
   "metadata": {},
   "source": [
    "## Name - Nilesh Dilip Lalge\n",
    "## Email - nileshlalge8394@gmail.com\n",
    "## Course - BE in CSE\n",
    "## Internship From - LetsGrowMore\n",
    "\n",
    "## Task 2 Develop A Neural Network That Can Read Handwriting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84541302-2130-4b74-8aa7-6ea4156df06b",
   "metadata": {},
   "source": [
    "# -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91358e3b",
   "metadata": {},
   "source": [
    "### We will be using MNIST data, this dataset actually 60000 training images and 10000 testing images, these are hand written digits we will classify the numbers from 0 to 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c9ec927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b28fab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset \n",
    "from tensorflow.keras.datasets import mnist\n",
    "#Load_data method - this will give 2 tuples one with training data and train target and other with test data and test target\n",
    "(X_train,y_train),(X_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d78f1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "232714cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d591cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e25d12f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d35885b340>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Label:{}\".format(y_train[3000]))\n",
    "plt.imshow(X_train[3000],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c340bcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         25,  91, 174, 254, 254, 255, 254, 156,  27,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  84,\n",
       "        212, 254, 254, 224, 216, 216, 219, 254, 103,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 172, 254,\n",
       "        250, 161,  56,  13,   0,   0,  58, 254, 176,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  69, 229, 254, 217,\n",
       "         78,   0,   0,   0,   0,   0, 176, 254, 107,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  44, 233, 254, 131,  10,\n",
       "          0,   0,   0,   0,   0,   0, 207, 206,   4,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 183, 254, 184,   2,   0,\n",
       "          0,   0,   0,   0,   0,   0, 165, 238, 127,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  85, 248, 247,  78,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0, 144, 254, 197,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   3, 188, 254, 123,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0, 102, 252, 254,  86,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 135, 254, 168,   7,   0,   0,   0,\n",
       "          0,   0,   0,   0,   9, 189, 254, 181,   2,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 198, 254,  78,   0,   0,   0,   0,\n",
       "          0,   0,   0,   4, 177, 254, 254, 169,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  24, 234, 254,  19,   0,   0,   0,   0,\n",
       "          0,   0,  10, 178, 254, 255, 254, 145,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  19, 225, 254, 124,  21,   0,   0,   5,\n",
       "         38, 132, 220, 252, 153, 244, 251,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 121, 250, 254, 229, 198, 198, 204,\n",
       "        254, 254, 245,  96,  35, 243, 196,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  85, 220, 254, 254, 254, 189,\n",
       "        143,  85,  10,   0, 169, 254, 140,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  11,  18,  18,  18,   3,\n",
       "          0,   0,   0,   6, 216, 254,  53,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  87, 254, 215,   9,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 170, 254, 140,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 198, 254, 113,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 198, 254, 113,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 198, 254, 113,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4e8abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "#We are representing our input as 28 X 28 image, hence we have 784 features that are explaining every images\n",
    "#We know that we have 10 classes as output\n",
    "#my input layer will have 784 neurons and output layer will have 10\n",
    "\n",
    "#Also I understand my features are 784, but they are represented in 28 X 28\n",
    "X_train = X_train.reshape(60000,784)\n",
    "X_test = X_test.reshape(10000,784)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02be4200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "0\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#Since the images are pixels ranging from 0 to 255, I will normalize them\n",
    "print(X_train.max())\n",
    "print(X_train.min())\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c36a63d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "#we also need to modify the target\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd75c52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[100])\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test,num_classes=10)\n",
    "print(y_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad24f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "#We will create Sequential model , and we are currently focussing on fully connected feed forward networks , \n",
    "#so for mentioning a layer to be fully connected we used something called Dense\n",
    "#Sequential is a model -- Dense is a layer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers,regularizers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aaaa54cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 2.1551 - accuracy: 0.3042\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 1.8303 - accuracy: 0.6077\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 1.4766 - accuracy: 0.7117\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 1.1633 - accuracy: 0.7652\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.9396 - accuracy: 0.7972\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.7924 - accuracy: 0.8194\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.6940 - accuracy: 0.8357\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.6247 - accuracy: 0.8478\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.5737 - accuracy: 0.8579\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.5343 - accuracy: 0.8654\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.5032 - accuracy: 0.8722\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.4779 - accuracy: 0.8771\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 1s 18ms/step - loss: 0.4569 - accuracy: 0.8814\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.4393 - accuracy: 0.8851\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.4243 - accuracy: 0.8877\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.4112 - accuracy: 0.8905\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3998 - accuracy: 0.8930\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3897 - accuracy: 0.8949\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3808 - accuracy: 0.8973\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3727 - accuracy: 0.8986\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3653 - accuracy: 0.8999\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3587 - accuracy: 0.9013\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3525 - accuracy: 0.9025\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3469 - accuracy: 0.9040\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3417 - accuracy: 0.9051\n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3367 - accuracy: 0.9063\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3321 - accuracy: 0.9076\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3279 - accuracy: 0.9086\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 1s 15ms/step - loss: 0.3237 - accuracy: 0.9094\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 0.3199 - accuracy: 0.9106\n",
      "Training Accuracy\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3176 - accuracy: 0.9113\n",
      "[0.3176010549068451, 0.9113333225250244]\n",
      "Test accuracy\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3034 - accuracy: 0.9161\n",
      "[0.3033580183982849, 0.916100025177002]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_nodes = 256\n",
    "output_layer_nodes = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_layer_nodes,input_shape=(784,),activation='relu'))\n",
    "model.add(Dense(hidden_layer_nodes,activation='relu'))\n",
    "model.add(Dense(output_layer_nodes,activation='softmax'))\n",
    "\n",
    "#we need to tell the model that its performing a classifcation problem so we need to compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=30,batch_size=1000,verbose=1)\n",
    "print(\"Training Accuracy\")\n",
    "print(model.evaluate(X_train,y_train))\n",
    "print(\"Test accuracy\")\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb1f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random initiazation and evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a926ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#How many parameters that our model is learning?\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f552da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Another version just to change the optimizer\n",
    "\n",
    "# hidden_layer_nodes = 256\n",
    "# output_layer_nodes = 10\n",
    "# model = Sequential()\n",
    "# model.add(Dense(hidden_layer_nodes,input_shape=(784,),activation='relu'))\n",
    "# model.add(Dense(hidden_layer_nodes,activation='relu'))\n",
    "# model.add(Dense(output_layer_nodes,activation='softmax'))\n",
    "# sgd = optimizers.SGD(learning_rate=0.01,momentum=0.9)\n",
    "# #As we discussed we need to tell the model that its performing a classifcation problem so we need to compile the model\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "# model.fit(X_train,y_train,epochs=30,batch_size=1000,verbose=1)\n",
    "# print(\"Training Accuracy\")\n",
    "# print(model.evaluate(X_train,y_train))\n",
    "# print(\"Test accuracy\")\n",
    "# print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5437f6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/60 [==============================] - 2s 20ms/step - loss: 2.2920 - accuracy: 0.1513\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 2.0856 - accuracy: 0.2779\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.8883 - accuracy: 0.3944\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.6856 - accuracy: 0.4801\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.5005 - accuracy: 0.5418\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.3455 - accuracy: 0.5853\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.2197 - accuracy: 0.6216\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.1263 - accuracy: 0.6497 \n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.0503 - accuracy: 0.6713\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.9885 - accuracy: 0.6900\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.9321 - accuracy: 0.7076\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8883 - accuracy: 0.7194\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8488 - accuracy: 0.7331\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8194 - accuracy: 0.7412\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7890 - accuracy: 0.7541\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7595 - accuracy: 0.7624\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.7409 - accuracy: 0.7698\n",
      "Epoch 18/30\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.7208 - accuracy: 0.7750\n",
      "Epoch 19/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6981 - accuracy: 0.7825\n",
      "Epoch 20/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6812 - accuracy: 0.7895\n",
      "Epoch 21/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6701 - accuracy: 0.7948\n",
      "Epoch 22/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6503 - accuracy: 0.8008\n",
      "Epoch 23/30\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.6429 - accuracy: 0.8022\n",
      "Epoch 24/30\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.6270 - accuracy: 0.8074\n",
      "Epoch 25/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.6208 - accuracy: 0.8107 0s - loss: 0.6227 - \n",
      "Epoch 26/30\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.6075 - accuracy: 0.8139\n",
      "Epoch 27/30\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.5978 - accuracy: 0.8181\n",
      "Epoch 28/30\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5811 - accuracy: 0.8213\n",
      "Epoch 29/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5782 - accuracy: 0.8245\n",
      "Epoch 30/30\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.5699 - accuracy: 0.8257\n",
      "Training Accuracy\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3761 - accuracy: 0.8954\n",
      "[0.3761311173439026, 0.895383358001709]\n",
      "Test accuracy\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8996\n",
      "[0.3588277995586395, 0.8996000289916992]\n"
     ]
    }
   ],
   "source": [
    "#Lets add dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "hidden_layer_nodes = 256\n",
    "output_layer_nodes = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_layer_nodes,input_shape=(784,),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_layer_nodes,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_layer_nodes,activation='softmax'))\n",
    "\n",
    "#we need to tell the model that its performing a classifcation problem so we need to compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=30,batch_size=1000,verbose=1)\n",
    "print(\"Training Accuracy\")\n",
    "print(model.evaluate(X_train,y_train))\n",
    "print(\"Test accuracy\")\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f159a52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5fee5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='accuracy',min_delta=0.01,patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5797512f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08400000000000002"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.4812-0.3972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b123aecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 2s 20ms/step - loss: 2.3325 - accuracy: 0.1317\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 2.1128 - accuracy: 0.2486\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.9232 - accuracy: 0.3704\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.7289 - accuracy: 0.4687\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.5355 - accuracy: 0.5353\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.3729 - accuracy: 0.5795\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 1.2357 - accuracy: 0.6196\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.1296 - accuracy: 0.6469\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 1.0480 - accuracy: 0.6720\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.9813 - accuracy: 0.6904\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 1s 21ms/step - loss: 0.9275 - accuracy: 0.7066\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 1s 20ms/step - loss: 0.8822 - accuracy: 0.7199\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 1s 19ms/step - loss: 0.8384 - accuracy: 0.7348\n",
      "Training Accuracy\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5547 - accuracy: 0.8630\n",
      "[0.554663360118866, 0.8629999756813049]\n",
      "Test accuracy\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.5328 - accuracy: 0.8697\n",
      "[0.5328418016433716, 0.869700014591217]\n"
     ]
    }
   ],
   "source": [
    "#Lets add dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "hidden_layer_nodes = 256\n",
    "output_layer_nodes = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_layer_nodes,input_shape=(784,),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_layer_nodes,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_layer_nodes,activation='softmax'))\n",
    "\n",
    "#we need to tell the model that its performing a classifcation problem so we need to compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=1000,callbacks=[early_stop],verbose=1)\n",
    "print(\"Training Accuracy\")\n",
    "print(model.evaluate(X_train,y_train))\n",
    "print(\"Test accuracy\")\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e42bf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 2.2938 - accuracy: 0.1427 - val_loss: 2.0806 - val_accuracy: 0.4629\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 2.0732 - accuracy: 0.2794 - val_loss: 1.8398 - val_accuracy: 0.6324\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 1.8739 - accuracy: 0.3990 - val_loss: 1.5904 - val_accuracy: 0.6960\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 1.6783 - accuracy: 0.4798 - val_loss: 1.3548 - val_accuracy: 0.7359\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 1.4996 - accuracy: 0.5354 - val_loss: 1.1541 - val_accuracy: 0.7685\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 1.3551 - accuracy: 0.5793 - val_loss: 0.9966 - val_accuracy: 0.7945\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 1.2317 - accuracy: 0.6132 - val_loss: 0.8757 - val_accuracy: 0.8145\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 1.1326 - accuracy: 0.6409 - val_loss: 0.7832 - val_accuracy: 0.8298\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 1.0518 - accuracy: 0.6668 - val_loss: 0.7128 - val_accuracy: 0.8405\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.9898 - accuracy: 0.6836 - val_loss: 0.6583 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.9360 - accuracy: 0.7009 - val_loss: 0.6133 - val_accuracy: 0.8561\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.8888 - accuracy: 0.7174 - val_loss: 0.5769 - val_accuracy: 0.8615\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.8448 - accuracy: 0.7318 - val_loss: 0.5476 - val_accuracy: 0.8659\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 2s 25ms/step - loss: 0.8133 - accuracy: 0.7429 - val_loss: 0.5226 - val_accuracy: 0.8695\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 2s 27ms/step - loss: 0.7807 - accuracy: 0.7546 - val_loss: 0.5002 - val_accuracy: 0.8746\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.7609 - accuracy: 0.7589 - val_loss: 0.4821 - val_accuracy: 0.8781\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 1s 25ms/step - loss: 0.7341 - accuracy: 0.7685 - val_loss: 0.4660 - val_accuracy: 0.8815\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.7149 - accuracy: 0.7743 - val_loss: 0.4526 - val_accuracy: 0.8843\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.6920 - accuracy: 0.7840 - val_loss: 0.4393 - val_accuracy: 0.8872\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.6757 - accuracy: 0.7886 - val_loss: 0.4283 - val_accuracy: 0.8894\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.6611 - accuracy: 0.7946 - val_loss: 0.4181 - val_accuracy: 0.8914\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.6431 - accuracy: 0.8019 - val_loss: 0.4084 - val_accuracy: 0.8927\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.6276 - accuracy: 0.8042 - val_loss: 0.3999 - val_accuracy: 0.8936\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.6193 - accuracy: 0.8092 - val_loss: 0.3921 - val_accuracy: 0.8949\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.6103 - accuracy: 0.8109 - val_loss: 0.3849 - val_accuracy: 0.8957\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5976 - accuracy: 0.8152 - val_loss: 0.3780 - val_accuracy: 0.8972\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5899 - accuracy: 0.8198 - val_loss: 0.3720 - val_accuracy: 0.8991\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5788 - accuracy: 0.8218 - val_loss: 0.3658 - val_accuracy: 0.9001\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5651 - accuracy: 0.8271 - val_loss: 0.3605 - val_accuracy: 0.9017\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5596 - accuracy: 0.8300 - val_loss: 0.3551 - val_accuracy: 0.9021\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5538 - accuracy: 0.8310 - val_loss: 0.3508 - val_accuracy: 0.9031\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 1s 24ms/step - loss: 0.5470 - accuracy: 0.8340 - val_loss: 0.3459 - val_accuracy: 0.9040\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5406 - accuracy: 0.8364 - val_loss: 0.3420 - val_accuracy: 0.9048\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 1s 23ms/step - loss: 0.5290 - accuracy: 0.8386 - val_loss: 0.3379 - val_accuracy: 0.9053\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 1s 22ms/step - loss: 0.5296 - accuracy: 0.8385 - val_loss: 0.3340 - val_accuracy: 0.9058\n",
      "Training Accuracy\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3479 - accuracy: 0.9021\n",
      "[0.34790053963661194, 0.9021499752998352]\n",
      "Test accuracy\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.9058\n",
      "[0.3339638411998749, 0.9057999849319458]\n"
     ]
    }
   ],
   "source": [
    "#Lets add dropout\n",
    "from tensorflow.keras.layers import Dropout\n",
    "hidden_layer_nodes = 256\n",
    "output_layer_nodes = 10\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden_layer_nodes,input_shape=(784,),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(hidden_layer_nodes,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(output_layer_nodes,activation='softmax'))\n",
    "\n",
    "#we need to tell the model that its performing a classifcation problem so we need to compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=1000,callbacks=[early_stop],validation_data=(X_test,y_test),verbose=1)\n",
    "print(\"Training Accuracy\")\n",
    "print(model.evaluate(X_train,y_train))\n",
    "print(\"Test accuracy\")\n",
    "print(model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2414640d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48217d1-f205-4e88-be52-5b6be7c205ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e492e702-5927-4c68-9c9f-2c7913fb7f31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
